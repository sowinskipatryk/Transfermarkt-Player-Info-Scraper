This scraper uses Selenium to get data from multiple pages by opening and closing the browser, which makes it incredibly slow. 
It's not the best solution but at least it works. 
The data is saved to .csv file temporarily and then exported to .xlsx when it finishes to hoard the data from the site. 
The result excel file can be downloaded from this repository so you don't need to flood the site with requests unless it's necessary.
